{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def get_df(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'Office_Products'\n",
    "RAW_PATH = os.path.join('./data/', DATASET)\n",
    "DATA_FILE = 'reviews_{}_5.json.gz'.format(DATASET)\n",
    "META_FILE = 'meta_{}.json.gz'.format(DATASET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "1. Load interaction data and item metadata\n",
    "2. Filter out unuseful items in metadata\n",
    "3. Calculate basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(27308) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(27312) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading interaction data into ./datasets/Office_Products\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100 17.6M  100 17.6M    0     0   779k      0  0:00:23  0:00:23 --:--:-- 1198k\n",
      "python(27662) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading item metadata into ./datasets/Office_Products\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100 45.3M  100 45.3M    0     0  1864k      0  0:00:24  0:00:24 --:--:-- 2819k\n"
     ]
    }
   ],
   "source": [
    "# download data if not exists\n",
    "\n",
    "if not os.path.exists(RAW_PATH):\n",
    "    subprocess.call('mkdir ' + RAW_PATH, shell=True)\n",
    "if not os.path.exists(os.path.join(RAW_PATH, DATA_FILE)):\n",
    "    print('Downloading interaction data into ' + RAW_PATH)\n",
    "    subprocess.call(\n",
    "        'cd {} && curl -O http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_{}_5.json.gz'\n",
    "        .format(RAW_PATH, DATASET), shell=True)\n",
    "if not os.path.exists(os.path.join(RAW_PATH, META_FILE)):\n",
    "    print('Downloading item metadata into ' + RAW_PATH)\n",
    "    subprocess.call(\n",
    "        'cd {} && curl -O http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/meta_{}.json.gz'\n",
    "        .format(RAW_PATH, DATASET), shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = get_df(os.path.join(RAW_PATH, DATA_FILE))\n",
    "data_df.head()\n",
    "\n",
    "asin_counts = data_df['asin'].value_counts()\n",
    "min_asin_frequency = asin_counts.min()\n",
    "\n",
    "reviewerName_counts = data_df['reviewerName'].value_counts()\n",
    "min_reviewerName_frequency = reviewerName_counts.min()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>imUrl</th>\n",
       "      <th>related</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>categories</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0078800242</td>\n",
       "      <td>All in one TeacherWorks Plus CD-ROM</td>\n",
       "      <td>93.06</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41K1aBkl...</td>\n",
       "      <td>{'buy_after_viewing': ['007861970X']}</td>\n",
       "      <td>{'Software': 18529}</td>\n",
       "      <td>[[Office Products, Office &amp; School Supplies, C...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0113000316</td>\n",
       "      <td>High quality inkjet cartridges use high-densit...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51AMwP3D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Office Products, Office &amp; School Supplies, P...</td>\n",
       "      <td>123GetInk -14-pack 5-black 3-cyan 3-magenta 3-...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>043928631X</td>\n",
       "      <td>Harry Potter living bookmark showing Harry, He...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/41SulB7T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Office Products, Office &amp; School Supplies, L...</td>\n",
       "      <td>Harry Potter Lenticular Hologram Bookmark - Ha...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0439340039</td>\n",
       "      <td>Windows based computer game.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51zQE0w%...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Software': 32784}</td>\n",
       "      <td>[[Office Products, Office &amp; School Supplies, E...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0439394058</td>\n",
       "      <td>126 pieces: 23\" tall schoolhouse calendar, 12 ...</td>\n",
       "      <td>11.64</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51DFp0Lg...</td>\n",
       "      <td>{'also_bought': ['B000QE1HHU', 'B00207MG4Y', '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Office Products, Office &amp; School Supplies, E...</td>\n",
       "      <td>Scholastic SC939405 All-In-One Schoolhouse Cal...</td>\n",
       "      <td>Scholastic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                        description  price  \\\n",
       "0  0078800242                All in one TeacherWorks Plus CD-ROM  93.06   \n",
       "1  0113000316  High quality inkjet cartridges use high-densit...    NaN   \n",
       "2  043928631X  Harry Potter living bookmark showing Harry, He...    NaN   \n",
       "3  0439340039                       Windows based computer game.    NaN   \n",
       "4  0439394058  126 pieces: 23\" tall schoolhouse calendar, 12 ...  11.64   \n",
       "\n",
       "                                               imUrl  \\\n",
       "0  http://ecx.images-amazon.com/images/I/41K1aBkl...   \n",
       "1  http://ecx.images-amazon.com/images/I/51AMwP3D...   \n",
       "2  http://ecx.images-amazon.com/images/I/41SulB7T...   \n",
       "3  http://ecx.images-amazon.com/images/I/51zQE0w%...   \n",
       "4  http://ecx.images-amazon.com/images/I/51DFp0Lg...   \n",
       "\n",
       "                                             related            salesRank  \\\n",
       "0              {'buy_after_viewing': ['007861970X']}  {'Software': 18529}   \n",
       "1                                                NaN                  NaN   \n",
       "2                                                NaN                  NaN   \n",
       "3                                                NaN  {'Software': 32784}   \n",
       "4  {'also_bought': ['B000QE1HHU', 'B00207MG4Y', '...                  NaN   \n",
       "\n",
       "                                          categories  \\\n",
       "0  [[Office Products, Office & School Supplies, C...   \n",
       "1  [[Office Products, Office & School Supplies, P...   \n",
       "2  [[Office Products, Office & School Supplies, L...   \n",
       "3  [[Office Products, Office & School Supplies, E...   \n",
       "4  [[Office Products, Office & School Supplies, E...   \n",
       "\n",
       "                                               title       brand  \n",
       "0                                                NaN         NaN  \n",
       "1  123GetInk -14-pack 5-black 3-cyan 3-magenta 3-...         NaN  \n",
       "2  Harry Potter Lenticular Hologram Bookmark - Ha...         NaN  \n",
       "3                                                NaN         NaN  \n",
       "4  Scholastic SC939405 All-In-One Schoolhouse Cal...  Scholastic  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df = get_df(os.path.join(RAW_PATH, META_FILE))\n",
    "meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only retain items that appear in interaction data\n",
    "\n",
    "useful_meta_df = meta_df[meta_df['asin'].isin(data_df['asin'])].reset_index(drop=True)\n",
    "all_items = set(useful_meta_df['asin'].values.tolist())\n",
    "\n",
    "def related_filter(related_dict):\n",
    "    out_dict = dict()\n",
    "    if related_dict is not np.nan:\n",
    "        for r in related_dict:\n",
    "            out_dict[r] = list(all_items & set(related_dict[r]))\n",
    "    return out_dict\n",
    "\n",
    "useful_meta_df['related'] = useful_meta_df['related'].apply(related_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = data_df['reviewerID'].value_counts().size\n",
    "n_items = data_df['asin'].value_counts().size\n",
    "n_clicks = len(data_df)\n",
    "min_time = data_df['unixReviewTime'].min()\n",
    "max_time = data_df['unixReviewTime'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Users: 4905\n",
      "# Items: 2420\n",
      "# Interactions: 53258\n",
      "Time Span: 2000-09-29/2014-07-23\n"
     ]
    }
   ],
   "source": [
    "time_format = '%Y-%m-%d'\n",
    "\n",
    "print('# Users:', n_users)\n",
    "print('# Items:', n_items)\n",
    "print('# Interactions:', n_clicks)\n",
    "print('Time Span: {}/{}'.format(\n",
    "    datetime.utcfromtimestamp(min_time).strftime(time_format),\n",
    "    datetime.utcfromtimestamp(max_time).strftime(time_format))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "salesRank      76.90%\n",
       "brand          19.88%\n",
       "price           2.73%\n",
       "description     1.61%\n",
       "title           0.12%\n",
       "asin            0.00%\n",
       "imUrl           0.00%\n",
       "related         0.00%\n",
       "categories      0.00%\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = useful_meta_df\n",
    "((df.isnull().sum())/df.shape[0]).sort_values(ascending=False).map(lambda x:\"{:.2%}\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dataset\n",
    "\n",
    "### Interaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00473363TJ8YSZ3YAGG9</td>\n",
       "      <td>B004APM26Q</td>\n",
       "      <td>1357430400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00473363TJ8YSZ3YAGG9</td>\n",
       "      <td>B0073W70BK</td>\n",
       "      <td>1357430400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00473363TJ8YSZ3YAGG9</td>\n",
       "      <td>B00007E7D2</td>\n",
       "      <td>1387843200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00473363TJ8YSZ3YAGG9</td>\n",
       "      <td>B007ZYF266</td>\n",
       "      <td>1387843200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00473363TJ8YSZ3YAGG9</td>\n",
       "      <td>B00D51XMLU</td>\n",
       "      <td>1387843200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id     item_id        time\n",
       "0  A00473363TJ8YSZ3YAGG9  B004APM26Q  1357430400\n",
       "1  A00473363TJ8YSZ3YAGG9  B0073W70BK  1357430400\n",
       "2  A00473363TJ8YSZ3YAGG9  B00007E7D2  1387843200\n",
       "3  A00473363TJ8YSZ3YAGG9  B007ZYF266  1387843200\n",
       "4  A00473363TJ8YSZ3YAGG9  B00D51XMLU  1387843200"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df = data_df.rename(columns={'asin': 'item_id', 'reviewerID': 'user_id', 'unixReviewTime': 'time'})\n",
    "out_df = out_df[['user_id', 'item_id', 'time']]\n",
    "out_df = out_df.drop_duplicates(['user_id', 'item_id', 'time'])\n",
    "out_df = out_df.sort_values(by=['user_id', 'time'], kind='mergesort').reset_index(drop=True)\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1357430400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1357430400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1387843200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1387843200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1387843200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id        time\n",
       "0        1        1  1357430400\n",
       "1        1        2  1357430400\n",
       "2        1        3  1387843200\n",
       "3        1        4  1387843200\n",
       "4        1        5  1387843200"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reindex (start from 1)\n",
    "\n",
    "# uids = sorted(out_df['user_id'].unique())\n",
    "uids = out_df['user_id'].unique()\n",
    "user2id = dict(zip(uids, range(1, len(uids) + 1)))\n",
    "# iids = sorted(out_df['item_id'].unique())\n",
    "iids = out_df['item_id'].unique()\n",
    "item2id = dict(zip(iids, range(1, len(iids) + 1)))\n",
    "\n",
    "out_df['user_id'] = out_df['user_id'].apply(lambda x: user2id[x])\n",
    "out_df['item_id'] = out_df['item_id'].apply(lambda x: item2id[x])\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_meta_df['item_id'] = useful_meta_df['asin'].apply(lambda x: item2id[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "out_df.to_csv(RAW_PATH+'/inter.csv', index=False)\n",
    "useful_meta_df.to_csv(RAW_PATH+'/meta.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "inter = pd.read_csv(RAW_PATH+'/inter.csv')\n",
    "useful_meta_df = pd.read_csv(RAW_PATH+'/meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq slide augmentation\n",
    "\n",
    "def prepare_data_augmentation(df):\n",
    "    max_item_list_len = 20\n",
    "\n",
    "    last_uid = None\n",
    "    uid_list, item_list, target, item_list_length = [], [], [], []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        uid, item_id = row['user_id'], row['item_id']\n",
    "        if last_uid != uid:\n",
    "            last_uid = uid\n",
    "            seq = []\n",
    "        else:\n",
    "            if len(seq) > max_item_list_len:\n",
    "                seq = seq[1:]\n",
    "            uid_list.append(uid)\n",
    "            item_list.append(seq[:])\n",
    "            target.append(item_id)\n",
    "            item_list_length.append(len(seq))\n",
    "        seq.append(item_id)\n",
    "\n",
    "    return uid_list, item_list, target, item_list_length\n",
    " \n",
    "\n",
    "uid_list, item_list, target, item_list_length = prepare_data_augmentation(inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "# useful_meta_df\n",
    "useful_meta_df['categories'] = useful_meta_df['categories'].apply(ast.literal_eval)\n",
    "useful_meta_df['categories'] = useful_meta_df['categories'].apply(lambda x: x[0][2:])\n",
    "columns_to_drop = ['asin', 'description','imUrl', 'related', 'salesRank']\n",
    "useful_meta_df_dropped = useful_meta_df.drop(columns=columns_to_drop)\n",
    "meta_dict = useful_meta_df_dropped.set_index('item_id').T.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "['Brownline 2013 Monthly Desk Pad Calendar, January - December, 22 x 17 Inches (C1731-13)']\n",
      "[1, 2]\n",
      "['Brownline 2013 Monthly Desk Pad Calendar, January - December, 22 x 17 Inches (C1731-13)', 'Panasonic KX-TG4741B DECT 6.0 Cordless Phone with Answering System, Black, 1 Handset']\n",
      "[1, 2, 3]\n",
      "['Brownline 2013 Monthly Desk Pad Calendar, January - December, 22 x 17 Inches (C1731-13)', 'Panasonic KX-TG4741B DECT 6.0 Cordless Phone with Answering System, Black, 1 Handset', 'Avery Self-Adhesive Laminating Sheets, 9 x 12 Inches, Box of 50 (73601)']\n",
      "[1, 2, 3, 4]\n",
      "['Brownline 2013 Monthly Desk Pad Calendar, January - December, 22 x 17 Inches (C1731-13)', 'Panasonic KX-TG4741B DECT 6.0 Cordless Phone with Answering System, Black, 1 Handset', 'Avery Self-Adhesive Laminating Sheets, 9 x 12 Inches, Box of 50 (73601)', 'Pilot B2P - Bottle to Pen - Retractable Ball Point Pens Made from Recycled Bottles, 2 Pen Pack, Fine Point, Black (32605)']\n",
      "[6]\n",
      "['Zebra Z-Grip  Retractable Ballpoing Pens Medium, 1.0 mm, Black Ink, Clear Barrel,  Box of 12 (22210)']\n",
      "[6, 7]\n",
      "['Zebra Z-Grip  Retractable Ballpoing Pens Medium, 1.0 mm, Black Ink, Clear Barrel,  Box of 12 (22210)', 'Scotch&reg; Bubble Mailer 7915-25-CS, 10.5 Inches x 15.25 Inches, Size 5, 25-Pack']\n",
      "[6, 7, 8]\n",
      "['Zebra Z-Grip  Retractable Ballpoing Pens Medium, 1.0 mm, Black Ink, Clear Barrel,  Box of 12 (22210)', 'Scotch&reg; Bubble Mailer 7915-25-CS, 10.5 Inches x 15.25 Inches, Size 5, 25-Pack', 'Avery Easy Peel Address Labels for Laser Printers, 1 x 2.625 Inches, White, Pack of 750 (05260)']\n",
      "[6, 7, 8, 9]\n",
      "['Zebra Z-Grip  Retractable Ballpoing Pens Medium, 1.0 mm, Black Ink, Clear Barrel,  Box of 12 (22210)', 'Scotch&reg; Bubble Mailer 7915-25-CS, 10.5 Inches x 15.25 Inches, Size 5, 25-Pack', 'Avery Easy Peel Address Labels for Laser Printers, 1 x 2.625 Inches, White, Pack of 750 (05260)', 'Scotch Magic Tape , 3/4 x 300 Inches, 3 Pack  (3105)']\n",
      "[11]\n",
      "['Rolodex Mesh Collection Jumbo Pencil Cup, Black (62557)']\n",
      "[11, 12]\n",
      "['Rolodex Mesh Collection Jumbo Pencil Cup, Black (62557)', 'Prismacolor Premier Pencil Sharpener']\n"
     ]
    }
   ],
   "source": [
    "prompt_input = {}\n",
    "for i in range(len(item_list)):\n",
    "    uid, items = uid_list[i], item_list[i]\n",
    "    # print([uid] + items)\n",
    "    key = \":\".join(map(str, [uid] + items))\n",
    "    title_list = []\n",
    "    for item in items:\n",
    "        title_list.append(meta_dict[item]['title'])\n",
    "    if i < 10:\n",
    "        print(items)\n",
    "        print(title_list)\n",
    "    formatted_titles = [f'<{title}>' for title in title_list]\n",
    "    formatted_string = '; '.join(formatted_titles)\n",
    "    prompt_input[key] = formatted_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(RAW_PATH+'/user_prompt_input.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(prompt_input, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_input = \"\"\"Assume you are an office products recommendation expert.\n",
    "You will be provided with a user's historical purchases of office products in chronological order, given in the following format:\n",
    "<The title of item1>; <The title of item2>; <The title of item3>;... \n",
    "Please conclude the user's preference in purchasing office products. Note that your response should be a coherent paragraph of no more than 100 words.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate item summray: what kind of users will like this item\n",
    "\n",
    "# step 1: find the sequences ending with the current item\n",
    "\n",
    "inter = pd.read_csv(RAW_PATH+'/inter.csv')\n",
    "useful_meta_df = pd.read_csv(RAW_PATH+'/meta.csv')\n",
    "useful_meta_df['brand'] = useful_meta_df['brand'].fillna('missing or unkown')\n",
    "useful_meta_df['title'] = useful_meta_df['title'].fillna('missing')\n",
    "useful_meta_df['description'] = useful_meta_df['description'].fillna('missing')\n",
    "import ast\n",
    "useful_meta_df['categories'] = useful_meta_df['categories'].apply(ast.literal_eval)\n",
    "useful_meta_df['categories'] = useful_meta_df['categories'].apply(lambda x: x[0][2:])\n",
    "columns_to_drop = ['asin', 'imUrl', 'related', 'salesRank']\n",
    "useful_meta_df_dropped = useful_meta_df.drop(columns=columns_to_drop)\n",
    "meta_dict = useful_meta_df_dropped.set_index('item_id').T.to_dict()\n",
    "\n",
    "# seq slide augmentation\n",
    "\n",
    "def prepare_data_augmentation(df):\n",
    "    max_item_list_len = 20\n",
    "\n",
    "    last_uid = None\n",
    "    uid_list, item_list, target, item_list_length = [], [], [], []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        uid, item_id = row['user_id'], row['item_id']\n",
    "        if last_uid != uid:\n",
    "            last_uid = uid\n",
    "            seq = []\n",
    "        else:\n",
    "            if len(seq) > max_item_list_len:\n",
    "                seq = seq[1:]\n",
    "            uid_list.append(uid)\n",
    "            item_list.append(seq[:])\n",
    "            target.append(item_id)\n",
    "            item_list_length.append(len(seq))\n",
    "        seq.append(item_id)\n",
    "\n",
    "    return uid_list, item_list, target, item_list_length\n",
    " \n",
    "\n",
    "uid_list, item_list, target, item_list_length = prepare_data_augmentation(inter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_list = [sublist[-11:] for sublist in item_list if (len(sublist) >= 2 and len(sublist) <= 21)]\n",
    "print(\"length of filtered_list\", len(filtered_list))\n",
    "\n",
    "last_values = set(sublist[-1] for sublist in filtered_list)\n",
    "\n",
    "end_dict = {value: [] for value in last_values}\n",
    "\n",
    "for sublist in filtered_list:\n",
    "    last_value = sublist[-1]\n",
    "    end_dict[last_value].append(sublist)\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "for key in end_dict:\n",
    "    if len(end_dict[key]) > 5:\n",
    "        end_dict[key] = random.sample(end_dict[key], 5)\n",
    "\n",
    "end_dict_text = {}\n",
    "for key in end_dict:\n",
    "    end_dict_text[key] = []\n",
    "    for ls in end_dict[key]:\n",
    "        ls_text = [meta_dict[item]['title'] for item in ls]\n",
    "        ls_text = [val for val in ls_text if val != \"missing\"]\n",
    "        end_dict_text[key].append(ls_text)\n",
    "\n",
    "\n",
    "end_dict_text_formatted = {}\n",
    "for item_id in end_dict_text.keys():\n",
    "    same_target_seqs = ''\n",
    "    for seq in end_dict_text[item_id]:\n",
    "        print(seq)\n",
    "        seq = ' -> '.join(seq) \n",
    "        seq = '[' + seq + '] # '\n",
    "        seq += \" \\n \"\n",
    "        same_target_seqs += seq\n",
    "    end_dict_text_formatted[item_id] = same_target_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_template(item_dict):\n",
    "    text = (\n",
    "        f\"The product name is {item_dict['title']}; \"\n",
    "        f\"brand is {item_dict['brand']}; \"\n",
    "        f\"categories are {item_dict['categories']}; \"\n",
    "        f\"price is {item_dict['price']}; \"\n",
    "        f\"The detailed description of the product is {item_dict['description'][:1000]}...\"\n",
    "    )\n",
    "    return text\n",
    "\n",
    "item_meta_formatted = {}\n",
    "for item_id in item2id.values():\n",
    "    item_meta_formatted[item_id] = item_template(meta_dict[item_id])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_prompt_gen(item_info, history):\n",
    "    prompt = f\"\"\"\n",
    "    Assume you are an office products recommendation expert. Please help me analyze a specific office product. You will be provided with the following information:\n",
    "    1) The attributes of the office product: {item_info};\n",
    "    2) The historical purchase information of users who have bought this product: {history}. Here, different sequences are separated by '#', and each sequence is in LIST format, representing a certain user's historical purchases. Items in each sequence are separated by '->', and the last item in all sequences is the specific product mentioned above.\n",
    "    \n",
    "    Requirements:\n",
    "    1) Please briefly describe the given target item.\n",
    "    2) Based on the provided sequences, please analyze what type of users would purchase this item. Please do not generally say office workers or people who like office supplies, as all users in this context have a need to purchase office supplies. Please provide a more detailed granularity.\n",
    "    Please provide your answer in JSON format, following this structure:\n",
    "    {{\n",
    "    \"item summary\": \"A description of the item, no more than 80 words.\", \n",
    "    \"potential user analysis\": \"what type of users would purchase this item, no more than 50 words.\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "item_prompt = {}\n",
    "for item_id in item2id.values():\n",
    "    item_info = item_meta_formatted[item_id]\n",
    "    if item_id in end_dict_text_formatted.keys():\n",
    "        history = end_dict_text_formatted[item_id]\n",
    "    else:\n",
    "        history = ' [None] '\n",
    "    item_prompt[item_id] = complete_prompt_gen(item_info, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(RAW_PATH+'/item_prompt_input.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(item_prompt, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inter = inter.drop(columns=['time'])\n",
    "\n",
    "inter.columns = ['user_id:token', 'item_id:token']\n",
    "\n",
    "inter.to_csv(RAW_PATH+'/Amazon_Office.inter', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(RAW_PATH+'/inter.csv')\n",
    "\n",
    "df = df.drop(columns=['time'])\n",
    "\n",
    "df.to_csv(RAW_PATH+'/Office.txt', sep=' ', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
