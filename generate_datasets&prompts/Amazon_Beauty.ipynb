{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f2369c2-d92d-4e3b-96cd-41083a4893a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ed4c3f5-8a4a-47b4-b331-2f308626f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def get_df(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efd6c0e0-50e8-4534-9298-35ad5bd4670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'Beauty'\n",
    "RAW_PATH = os.path.join('./data/', DATASET)\n",
    "DATA_FILE = 'reviews_{}_5.json.gz'.format(DATASET)\n",
    "META_FILE = 'meta_{}.json.gz'.format(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86e55849-58e4-42a2-ade6-15e42e315623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data if not exists\n",
    "\n",
    "if not os.path.exists(RAW_PATH):\n",
    "    subprocess.call('mkdir ' + RAW_PATH, shell=True)\n",
    "if not os.path.exists(os.path.join(RAW_PATH, DATA_FILE)):\n",
    "    print('Downloading interaction data into ' + RAW_PATH)\n",
    "    subprocess.call(\n",
    "        'cd {} && curl -O http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_{}_5.json.gz'\n",
    "        .format(RAW_PATH, DATASET), shell=True)\n",
    "if not os.path.exists(os.path.join(RAW_PATH, META_FILE)):\n",
    "    print('Downloading item metadata into ' + RAW_PATH)\n",
    "    subprocess.call(\n",
    "        'cd {} && curl -O http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/meta_{}.json.gz'\n",
    "        .format(RAW_PATH, DATASET), shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6557474-45be-4269-8a1a-568bce64aaee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1YJEY40YUW4SE</td>\n",
       "      <td>7806397051</td>\n",
       "      <td>Andrea</td>\n",
       "      <td>[3, 4]</td>\n",
       "      <td>Very oily and creamy. Not at all what I expect...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>1391040000</td>\n",
       "      <td>01 30, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A60XNB876KYML</td>\n",
       "      <td>7806397051</td>\n",
       "      <td>Jessica H.</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>This palette was a decent price and I was look...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>OK Palette!</td>\n",
       "      <td>1397779200</td>\n",
       "      <td>04 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3G6XNM240RMWA</td>\n",
       "      <td>7806397051</td>\n",
       "      <td>Karen</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>The texture of this concealer pallet is fantas...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>great quality</td>\n",
       "      <td>1378425600</td>\n",
       "      <td>09 6, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1PQFP6SAJ6D80</td>\n",
       "      <td>7806397051</td>\n",
       "      <td>Norah</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>I really can't tell what exactly this thing is...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Do not work on my face</td>\n",
       "      <td>1386460800</td>\n",
       "      <td>12 8, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A38FVHZTNQ271F</td>\n",
       "      <td>7806397051</td>\n",
       "      <td>Nova Amor</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>It was a little smaller than I expected, but t...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>It's okay.</td>\n",
       "      <td>1382140800</td>\n",
       "      <td>10 19, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin reviewerName helpful  \\\n",
       "0  A1YJEY40YUW4SE  7806397051       Andrea  [3, 4]   \n",
       "1   A60XNB876KYML  7806397051   Jessica H.  [1, 1]   \n",
       "2  A3G6XNM240RMWA  7806397051        Karen  [0, 1]   \n",
       "3  A1PQFP6SAJ6D80  7806397051        Norah  [2, 2]   \n",
       "4  A38FVHZTNQ271F  7806397051    Nova Amor  [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Very oily and creamy. Not at all what I expect...      1.0   \n",
       "1  This palette was a decent price and I was look...      3.0   \n",
       "2  The texture of this concealer pallet is fantas...      4.0   \n",
       "3  I really can't tell what exactly this thing is...      2.0   \n",
       "4  It was a little smaller than I expected, but t...      3.0   \n",
       "\n",
       "                  summary  unixReviewTime   reviewTime  \n",
       "0  Don't waste your money      1391040000  01 30, 2014  \n",
       "1             OK Palette!      1397779200  04 18, 2014  \n",
       "2           great quality      1378425600   09 6, 2013  \n",
       "3  Do not work on my face      1386460800   12 8, 2013  \n",
       "4              It's okay.      1382140800  10 19, 2013  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = get_df(os.path.join(RAW_PATH, DATA_FILE))\n",
    "meta_df = get_df(os.path.join(RAW_PATH, META_FILE))\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07b39a1d-253e-4cb2-9b7f-506433eeedd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Users: 22363\n",
      "# Items: 12101\n",
      "# Interactions: 198502\n",
      "Time Span: 2002-06-12/2014-07-23\n",
      "(198502, 9)\n",
      "========after filtering=============\n",
      "# Users: 22363\n",
      "# Items: 12101\n",
      "# Interactions: 198502\n",
      "Time Span: 2002-06-12/2014-07-23\n"
     ]
    }
   ],
   "source": [
    "def filter_df(df):\n",
    "    while True:\n",
    "        print(df.shape)\n",
    "        \n",
    "        asin_counts = df['asin'].value_counts()\n",
    "        reviewerName_counts = df['reviewerID'].value_counts()\n",
    "\n",
    "       \n",
    "        asin_to_remove = asin_counts[asin_counts < 5].index\n",
    "        reviewerName_to_remove = reviewerName_counts[reviewerName_counts < 5].index\n",
    "\n",
    "        \n",
    "        if len(asin_to_remove) == 0 and len(reviewerName_to_remove) == 0:\n",
    "            break\n",
    "\n",
    "       \n",
    "        df = df[~df['asin'].isin(asin_to_remove)]\n",
    "        df = df[~df['reviewerID'].isin(reviewerName_to_remove)]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "n_users = data_df['reviewerID'].value_counts().size\n",
    "n_items = data_df['asin'].value_counts().size\n",
    "n_clicks = len(data_df)\n",
    "min_time = data_df['unixReviewTime'].min()\n",
    "max_time = data_df['unixReviewTime'].max()\n",
    "time_format = '%Y-%m-%d'\n",
    "\n",
    "print('# Users:', n_users)\n",
    "print('# Items:', n_items)\n",
    "print('# Interactions:', n_clicks)\n",
    "print('Time Span: {}/{}'.format(\n",
    "    datetime.utcfromtimestamp(min_time).strftime(time_format),\n",
    "    datetime.utcfromtimestamp(max_time).strftime(time_format))\n",
    ")\n",
    "\n",
    "data_df = filter_df(data_df)\n",
    "\n",
    "print(\"========after filtering=============\")\n",
    "n_users = data_df['reviewerID'].value_counts().size\n",
    "n_items = data_df['asin'].value_counts().size\n",
    "n_clicks = len(data_df)\n",
    "min_time = data_df['unixReviewTime'].min()\n",
    "max_time = data_df['unixReviewTime'].max()\n",
    "time_format = '%Y-%m-%d'\n",
    "\n",
    "print('# Users:', n_users)\n",
    "print('# Items:', n_items)\n",
    "print('# Interactions:', n_clicks)\n",
    "print('Time Span: {}/{}'.format(\n",
    "    datetime.utcfromtimestamp(min_time).strftime(time_format),\n",
    "    datetime.utcfromtimestamp(max_time).strftime(time_format))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82af4a90-40df-45c0-ba0e-8f0b26ec39d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only retain items that appear in interaction data\n",
    "meta_df = get_df(os.path.join(RAW_PATH, META_FILE))\n",
    "\n",
    "useful_meta_df = meta_df[meta_df['asin'].isin(data_df['asin'])].reset_index(drop=True)\n",
    "all_items = set(useful_meta_df['asin'].values.tolist())\n",
    "\n",
    "def related_filter(related_dict):\n",
    "    out_dict = dict()\n",
    "    if related_dict is not np.nan:\n",
    "        for r in related_dict:\n",
    "            out_dict[r] = list(all_items & set(related_dict[r]))\n",
    "    return out_dict\n",
    "\n",
    "useful_meta_df['related'] = useful_meta_df['related'].apply(related_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d67c3729-6481-4558-a811-140ab7a09f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brand          17.12%\n",
       "price           4.82%\n",
       "salesRank       1.73%\n",
       "description     1.70%\n",
       "title           0.06%\n",
       "imUrl           0.06%\n",
       "asin            0.00%\n",
       "categories      0.00%\n",
       "related         0.00%\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = useful_meta_df\n",
    "((df.isnull().sum())/df.shape[0]).sort_values(ascending=False).map(lambda x:\"{:.2%}\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6d89d6-7384-4deb-82cb-d0b778072a0b",
   "metadata": {},
   "source": [
    "# Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f76e6d4e-2444-4ccc-abe6-df2cb5fb590e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B007IY97U0</td>\n",
       "      <td>1405296000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B00870XLDS</td>\n",
       "      <td>1405296000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B008MIRO88</td>\n",
       "      <td>1405296000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B00BQYYMN0</td>\n",
       "      <td>1405296000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A00414041RD0BXM6WK0GX</td>\n",
       "      <td>B00GRTQBTM</td>\n",
       "      <td>1405296000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 user_id     item_id        time\n",
       "0  A00414041RD0BXM6WK0GX  B007IY97U0  1405296000\n",
       "1  A00414041RD0BXM6WK0GX  B00870XLDS  1405296000\n",
       "2  A00414041RD0BXM6WK0GX  B008MIRO88  1405296000\n",
       "3  A00414041RD0BXM6WK0GX  B00BQYYMN0  1405296000\n",
       "4  A00414041RD0BXM6WK0GX  B00GRTQBTM  1405296000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df = data_df.rename(columns={'asin': 'item_id', 'reviewerID': 'user_id', 'unixReviewTime': 'time'})\n",
    "out_df = out_df[['user_id', 'item_id', 'time']]\n",
    "out_df = out_df.drop_duplicates(['user_id', 'item_id', 'time'])\n",
    "out_df = out_df.sort_values(by=['user_id', 'time'], kind='mergesort').reset_index(drop=True)\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16cfc97e-5407-46dc-afb8-8eab13122b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1405296000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1405296000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1405296000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1405296000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1405296000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id        time\n",
       "0        1        1  1405296000\n",
       "1        1        2  1405296000\n",
       "2        1        3  1405296000\n",
       "3        1        4  1405296000\n",
       "4        1        5  1405296000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reindex (start from 1)\n",
    "# uids = sorted(out_df['user_id'].unique())\n",
    "uids = out_df['user_id'].unique()\n",
    "user2id = dict(zip(uids, range(1, len(uids) + 1)))\n",
    "# iids = sorted(out_df['item_id'].unique())\n",
    "iids = out_df['item_id'].unique()\n",
    "item2id = dict(zip(iids, range(1, len(iids) + 1)))\n",
    "\n",
    "out_df['user_id'] = out_df['user_id'].apply(lambda x: user2id[x])\n",
    "out_df['item_id'] = out_df['item_id'].apply(lambda x: item2id[x])\n",
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f691263-2988-4ae1-9f49-ba1ca838305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(RAW_PATH+'/item2id.json', 'w') as f:\n",
    "    json.dump(item2id, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97d65c1d-ed3b-4970-b7a9-9845786d4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "useful_meta_df['item_id'] = useful_meta_df['asin'].apply(lambda x: item2id[x])\n",
    "# save data\n",
    "out_df.to_csv(RAW_PATH+'/inter.csv', index=False)\n",
    "useful_meta_df.to_csv(RAW_PATH+'/meta.csv', index=False)\n",
    "\n",
    "inter = out_df.drop(columns=['time'])\n",
    "inter.columns = ['user_id:token', 'item_id:token']\n",
    "inter.to_csv(RAW_PATH+'/Amazon_'+DATASET+'.inter', sep='\\t', index=False)\n",
    "\n",
    "df_txt = out_df.drop(columns=['time'])\n",
    "df_txt.to_csv(RAW_PATH+'/'+ DATASET+'.txt', sep=' ', index=False, header=False)\n",
    "\n",
    "\n",
    "# def transform_input(input_file, output_file):\n",
    "#     with open(input_file, 'r') as file:\n",
    "#         lines = file.readlines()\n",
    "\n",
    "#     data = {}\n",
    "#     for line in lines:\n",
    "#         key, value = line.strip().split()\n",
    "#         key, value = int(key), int(value)\n",
    "#         if key not in data:\n",
    "#             data[key] = []\n",
    "#         data[key].append(value)\n",
    "\n",
    "#     with open(output_file, 'w') as file:\n",
    "#         for key in sorted(data.keys()):\n",
    "#             file.write(f\"{key} {' '.join(map(str, data[key]))}\\n\")\n",
    "\n",
    "# input_file = RAW_PATH+'/'+ DATASET+'.txt'\n",
    "# output_file = RAW_PATH+'/'+ DATASET+'_icsrec.txt'\n",
    "# transform_input(input_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f38bd0-a61a-44a6-9c54-157727092651",
   "metadata": {},
   "source": [
    "# User Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d274d095-f354-48d8-8a78-d3a60774f9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "['63cm Long Zipper Beige+pink Wavy Cosplay Hair Wig Rw157']\n",
      "[1, 2]\n",
      "['63cm Long Zipper Beige+pink Wavy Cosplay Hair Wig Rw157', 'MapofBeauty Long Wave Curly Hair Wig Full Wig for Women Long (Black)']\n",
      "[1, 2, 3]\n",
      "['63cm Long Zipper Beige+pink Wavy Cosplay Hair Wig Rw157', 'MapofBeauty Long Wave Curly Hair Wig Full Wig for Women Long (Black)', 'MapofBeauty Cosplay Costume Long Curly Hair Wig Ladies Synthetic Wigs (White)']\n",
      "[1, 2, 3, 4]\n",
      "['63cm Long Zipper Beige+pink Wavy Cosplay Hair Wig Rw157', 'MapofBeauty Long Wave Curly Hair Wig Full Wig for Women Long (Black)', 'MapofBeauty Cosplay Costume Long Curly Hair Wig Ladies Synthetic Wigs (White)', '32&quot; 80cm Long Hair Heat Resistant Spiral Curly Cosplay Wig (Red Dark)']\n",
      "[1, 2, 3, 4, 5]\n",
      "['63cm Long Zipper Beige+pink Wavy Cosplay Hair Wig Rw157', 'MapofBeauty Long Wave Curly Hair Wig Full Wig for Women Long (Black)', 'MapofBeauty Cosplay Costume Long Curly Hair Wig Ladies Synthetic Wigs (White)', '32&quot; 80cm Long Hair Heat Resistant Spiral Curly Cosplay Wig (Red Dark)', 'MapofBeauty 28&quot; 70cm Long Curly Hair Ends Costume Cosplay Wig (Brown)']\n",
      "[7]\n",
      "['NOW Foods Oil Of Oregano 25%, 1 ounce']\n",
      "[7, 8]\n",
      "['NOW Foods Oil Of Oregano 25%, 1 ounce', 'Ecotools Bamboo Bristle Bath Brush']\n",
      "[7, 8, 9]\n",
      "['NOW Foods Oil Of Oregano 25%, 1 ounce', 'Ecotools Bamboo Bristle Bath Brush', 'Healthy Hair Plus - Anti Fungal Shampoo - 12oz']\n",
      "[7, 8, 9, 10]\n",
      "['NOW Foods Oil Of Oregano 25%, 1 ounce', 'Ecotools Bamboo Bristle Bath Brush', 'Healthy Hair Plus - Anti Fungal Shampoo - 12oz', 'ALICE 10 Pcs Vogue Nail Care Personal Manicure &amp; Pedicure Set, Travel &amp; Grooming Kit BROWN']\n",
      "[7, 8, 9, 10, 11]\n",
      "['NOW Foods Oil Of Oregano 25%, 1 ounce', 'Ecotools Bamboo Bristle Bath Brush', 'Healthy Hair Plus - Anti Fungal Shampoo - 12oz', 'ALICE 10 Pcs Vogue Nail Care Personal Manicure &amp; Pedicure Set, Travel &amp; Grooming Kit BROWN', 'Herbal Essences Smooth Collection Shampoo 13.5 Fl Oz']\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "inter = pd.read_csv(RAW_PATH+'/inter.csv')\n",
    "useful_meta_df = pd.read_csv(RAW_PATH+'/meta.csv')\n",
    "\n",
    "# seq slide augmentation\n",
    "\n",
    "def prepare_data_augmentation(df):\n",
    "    max_item_list_len = 20\n",
    "\n",
    "    last_uid = None\n",
    "    uid_list, item_list, target, item_list_length = [], [], [], []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        uid, item_id = row['user_id'], row['item_id']\n",
    "        if last_uid != uid:\n",
    "            last_uid = uid\n",
    "            seq = []\n",
    "        else:\n",
    "            if len(seq) > max_item_list_len:\n",
    "                seq = seq[1:]\n",
    "            uid_list.append(uid)\n",
    "            item_list.append(seq[:])\n",
    "            target.append(item_id)\n",
    "            item_list_length.append(len(seq))\n",
    "        seq.append(item_id)\n",
    "\n",
    "    return uid_list, item_list, target, item_list_length\n",
    " \n",
    "\n",
    "uid_list, item_list, target, item_list_length = prepare_data_augmentation(inter)\n",
    "\n",
    "\n",
    "import ast\n",
    "# useful_meta_df\n",
    "useful_meta_df['categories'] = useful_meta_df['categories'].apply(ast.literal_eval)\n",
    "useful_meta_df['categories'] = useful_meta_df['categories'].apply(lambda x: x[0][2:])\n",
    "# columns_to_drop = ['asin', 'description','imUrl', 'related', 'salesRank']\n",
    "columns_to_drop = ['asin', 'description','imUrl', 'related']\n",
    "useful_meta_df_dropped = useful_meta_df.drop(columns=columns_to_drop)\n",
    "meta_dict = useful_meta_df_dropped.set_index('item_id').T.to_dict()\n",
    "\n",
    "requests = {}\n",
    "for i in range(len(item_list)):\n",
    "    uid, items = uid_list[i], item_list[i]\n",
    "    # print([uid] + items)\n",
    "    key = \":\".join(map(str, [uid] + items))\n",
    "    title_list = []\n",
    "    for item in items:\n",
    "        title_list.append(meta_dict[item]['title'])\n",
    "    if i < 10:\n",
    "        print(items)\n",
    "        print(title_list)\n",
    "    formatted_titles = [f'<{title}>' for title in title_list]\n",
    "    formatted_string = '; '.join(formatted_titles)\n",
    "    requests[key] = formatted_string\n",
    "\n",
    "import pickle\n",
    "with open(RAW_PATH+'/user_prompt_input.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(requests, pickle_file)\n",
    "    \n",
    "# with open(RAW_PATH+\"/user_prompt_input.pkl\", 'rb') as pickle_file:\n",
    "#     question_dic = pickle.load(pickle_file)\n",
    "\n",
    "system_input = \"\"\"Assume you are a beauty products recommendation expert.\n",
    "You will be provided with a user's historical purchases of beauty products in chronological order, given in the following format:\n",
    "<The title of item1>; <The title of item2>; <The title of item3>;... \n",
    "Please summarize the user's specific preference when purchasing beauty products. Note that your response should be a coherent paragraph of no more than 100 words.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f5f730-393b-4cd6-9678-a8bff73add27",
   "metadata": {},
   "source": [
    "# Item Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ef65dbd-fb3a-4b2e-8969-35b68f99d73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = pd.read_csv(RAW_PATH+'/inter.csv')\n",
    "useful_meta_df = pd.read_csv(RAW_PATH+'/meta.csv')\n",
    "\n",
    "useful_meta_df['brand'] = useful_meta_df['brand'].fillna('missing')\n",
    "useful_meta_df['salesRank'] = useful_meta_df['salesRank'].fillna('missing')\n",
    "useful_meta_df['title'] = useful_meta_df['title'].fillna('missing')\n",
    "useful_meta_df['description'] = useful_meta_df['description'].fillna('missing')\n",
    "useful_meta_df['price'] = useful_meta_df['price'].fillna('missing')\n",
    "import ast\n",
    "useful_meta_df['categories'] = useful_meta_df['categories'].apply(ast.literal_eval)\n",
    "useful_meta_df['categories'] = useful_meta_df['categories'].apply(lambda x: x[0][2:])\n",
    "# columns_to_drop = ['asin', 'imUrl', 'related', 'salesRank']\n",
    "columns_to_drop = ['asin', 'imUrl', 'related', ]\n",
    "useful_meta_df_dropped = useful_meta_df.drop(columns=columns_to_drop)\n",
    "meta_dict = useful_meta_df_dropped.set_index('item_id').T.to_dict()\n",
    "\n",
    "# seq slide augmentation\n",
    "\n",
    "def prepare_data_augmentation(df):\n",
    "    max_item_list_len = 20\n",
    "\n",
    "    last_uid = None\n",
    "    uid_list, item_list, target, item_list_length = [], [], [], []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        uid, item_id = row['user_id'], row['item_id']\n",
    "        if last_uid != uid:\n",
    "            last_uid = uid\n",
    "            seq = []\n",
    "        else:\n",
    "            if len(seq) > max_item_list_len:\n",
    "                seq = seq[1:]\n",
    "            uid_list.append(uid)\n",
    "            item_list.append(seq[:])\n",
    "            target.append(item_id)\n",
    "            item_list_length.append(len(seq))\n",
    "        seq.append(item_id)\n",
    "\n",
    "    return uid_list, item_list, target, item_list_length\n",
    " \n",
    "\n",
    "uid_list, item_list, target, item_list_length = prepare_data_augmentation(inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4fe52be-d177-4f06-8e9c-bf25f955feb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of filtered_list 153776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtered_list = [sublist[-11:] for sublist in item_list if (len(sublist) >= 2 and len(sublist) <= 21)]\n",
    "print(\"length of filtered_list\", len(filtered_list))\n",
    "\n",
    "last_values = set(sublist[-1] for sublist in filtered_list)\n",
    "\n",
    "end_dict = {value: [] for value in last_values}\n",
    "\n",
    "for sublist in filtered_list:\n",
    "    last_value = sublist[-1]\n",
    "    end_dict[last_value].append(sublist)\n",
    "\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "for key in end_dict:\n",
    "    if len(end_dict[key]) > 5:\n",
    "        end_dict[key] = random.sample(end_dict[key], 5)\n",
    "\n",
    "end_dict_text = {}\n",
    "for key in end_dict:\n",
    "    end_dict_text[key] = []\n",
    "    for ls in end_dict[key]:\n",
    "        ls_text = [meta_dict[item]['title'] for item in ls]\n",
    "        ls_text = [val for val in ls_text if val != \"missing\"]\n",
    "        end_dict_text[key].append(ls_text)\n",
    "\n",
    "\n",
    "end_dict_text_formatted = {}\n",
    "for item_id in end_dict_text.keys():\n",
    "    same_target_seqs = ''\n",
    "    for seq in end_dict_text[item_id]:\n",
    "        print(seq)\n",
    "        seq = ' -> '.join(seq) \n",
    "        seq = '[' + seq + '] # '\n",
    "        seq += \" \\n \"\n",
    "        same_target_seqs += seq\n",
    "    end_dict_text_formatted[item_id] = same_target_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "117301f4-fd52-47ec-9ebb-8e7d78806de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_template(item_dict):\n",
    "    text = (\n",
    "        f\"The product name is {item_dict['title']}; \"\n",
    "        f\"brand is {item_dict['brand']}; \"\n",
    "        f\"categories are {item_dict['categories']}; \"\n",
    "        f\"salesRank is {item_dict['salesRank']}; \"\n",
    "        f\"price is {item_dict['price']}; \"\n",
    "        f\"The detailed description of the product is {item_dict['description'][:500]}......\"\n",
    "    )\n",
    "    return text\n",
    "\n",
    "item_meta_formatted = {}\n",
    "for item_id in item2id.values():\n",
    "    item_meta_formatted[item_id] = item_template(meta_dict[item_id])\n",
    "    \n",
    "def complete_prompt_gen(item_info, history):\n",
    "    prompt = f\"\"\"\n",
    "    Assume you are a Beauty products recommendation expert. Please help me analyze a specific Beauty product. You will be provided with the following information:\n",
    "    1) The basic information of the Beauty product: {item_info};\n",
    "    2) The historical purchase information of users who have bought this product: {history}. Here, different sequences are separated by '#', and each sequence is in LIST format, representing a certain user's historical purchases. Items in each sequence are separated by '->', and the last item in all sequences is the specific product mentioned above.\n",
    "    \n",
    "    Requirements:\n",
    "    1) Please briefly describe the given Beauty product.\n",
    "    2) Based on the provided sequences, please analyze what type of users would purchase this specific product. Please do not generally say makeup enthusiasts, as all users in this context have a need to purchase Beauty products. Instead, please provide a more detailed granularity.\n",
    "    Please provide your answer in JSON format, following this structure:\n",
    "    {{\n",
    "    \"item summary\": \"A description of the item, no more than 80 words.\", \n",
    "    \"potential user analysis\": \"what type of users would purchase this item, no more than 50 words.\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "item_prompt = {}\n",
    "for item_id in item2id.values():\n",
    "    item_info = item_meta_formatted[item_id]\n",
    "    if item_id in end_dict_text_formatted.keys():\n",
    "        history = end_dict_text_formatted[item_id]\n",
    "    else:\n",
    "        history = ' [None] '\n",
    "    item_prompt[item_id] = complete_prompt_gen(item_info, history)\n",
    "\n",
    "import pickle\n",
    "with open(RAW_PATH+'/item_prompt_input.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(item_prompt, pickle_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
